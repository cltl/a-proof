{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging annotated Covid data with raw notes\n",
    "\n",
    "This notebook reads the extracted covid annotations (i.e. the output of `annotation_extraction_cov.ipynb`). It then matches these notes up with the raw patient records from 2020, using patient and note ID numbers. This **provides the date-time stamp for each note, which is essential for timeseries analysis**. \n",
    "\n",
    "\n",
    "Be warned, this notebook shows all of the \"working out\" steps. There were multiple versions of the original patient records with different structures and no column names. A lot of this notebook is just me trying to figure out which columns are which and match them up with the annotated sentences. A sneaky shift-index-by-one issue made this tricky, but it worked in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "# Make graphics nice\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Set sensible defaults\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the annotated covid data\n",
    "df_annot = pd.read_csv('~/gianluca_data/data/covid_traindata.tsv', sep='\\t')\n",
    "print(df_annot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot.head(4).src_file.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_source(row):\n",
    "    centre, srcid, pid, nid, mysid, date, batch, suff = row.src_file.split(\"--\")\n",
    "    srcid = int(srcid) - 1\n",
    "    return centre, int(srcid), int(pid), int(nid), int(mysid), date, batch\n",
    "    \n",
    "# Parse the src_file field into new columns with corresponding information\n",
    "df_par = pd.DataFrame(df_annot.apply(parse_source, axis=1).to_list(), columns=[\n",
    "        'centre', 'src_id', 'patient_id', 'note_id', 'mystery_id', 'date', 'batch'])\n",
    "df_annot = pd.concat([df_annot, df_par], axis=1)\n",
    "df_annot.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot.drop('src_file', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the raw covid notes\n",
    "\n",
    "covid_dir = '//data/bestanden 2020/'\n",
    "\n",
    "covid_files = [\n",
    "    'Notities AMC 2020 Q3.csv',\n",
    "    'Notities VUMC 2020 Q1.csv',\n",
    "    'Notities VUMC 2020 Q2.csv',\n",
    "    'Notities AMC 2020 Q1.csv',\n",
    "    'Notities VUMC 2020 Q3.csv',\n",
    "    'Notities AMC 2020 Q2.csv',\n",
    "]\n",
    "\n",
    "covid_files = [covid_dir + c for c in covid_files]\n",
    "\n",
    "def load_notes(fpath):\n",
    "    try:\n",
    "        col_names = ['mdn', 'note_id', 'note_csn', 'type', 'date', 'note', 'other1', 'other2']\n",
    "        df = pd.read_csv(fpath, sep=';', names=col_names, index_col=False)\n",
    "        df.drop(['other1', 'other2'], axis=1, inplace=True)\n",
    "        df['source_file'] = fpath.split('/')[-1]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {fpath}\\t{e}\")\n",
    "\n",
    "dfs = []\n",
    "for fpath in tqdm(covid_files):\n",
    "    dfs.append(load_notes(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes = pd.concat(dfs)\n",
    "print(df_notes.shape)\n",
    "df_notes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try figure out which IDs are which\n",
    "for id1 in ['mdn', 'note_id', 'note_csn']:\n",
    "    for id2 in ['src_id', 'patient_id', 'note_id', 'mystery_id']:\n",
    "        print(id1, id2, np.intersect1d(df_notes[id1].unique(), df_annot[id2].unique()).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot.patient_id.nunique(), df_annot.note_id.nunique(), df_annot.mystery_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the annotated and raw notes to check correspondence\n",
    "df_merged = df_annot.merge(df_notes, how='outer', left_on=['note_id', 'patient_id', 'date'], right_on=['note_id', 'mdn', 'date'])\n",
    "df_merged.to_csv('~/gianluca_data/data/covid_traindata_matched.tsv', sep='\\t', index=False)\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_merged.columns:\n",
    "    print(c, df_merged[c].nunique(), sep='\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check (output redacted for patient privacy)\n",
    "print(df_merged[(df_merged.patient_id == 1831037) & (df_merged.note_id == 422549521)].sentence.values)\n",
    "print(df_merged[(df_merged.patient_id == 1831037) & (df_merged.note_id == 422549521)].head(1).note.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
