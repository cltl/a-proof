{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-0.3.5.1.tar.gz (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 902 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "\u001b[K     |████████████████████████████████| 769 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from sentence_transformers) (4.42.1)\n",
      "Requirement already satisfied: torch>=1.2.0 in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from sentence_transformers) (1.6.0)\n",
      "Requirement already satisfied: numpy in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from sentence_transformers) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from sentence_transformers) (0.22.1)\n",
      "Requirement already satisfied: scipy in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from sentence_transformers) (1.4.1)\n",
      "Requirement already satisfied: nltk in /Users/piek/.local/lib/python3.7/site-packages (from sentence_transformers) (3.5)\n",
      "Requirement already satisfied: filelock in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->sentence_transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->sentence_transformers) (20.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/piek/.local/lib/python3.7/site-packages (from transformers==3.0.2->sentence_transformers) (2020.6.8)\n",
      "Requirement already satisfied: requests in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from transformers==3.0.2->sentence_transformers) (2.22.0)\n",
      "Processing /Users/piek/Library/Caches/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0/sacremoses-0.0.43-py3-none-any.whl\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.91-cp37-cp37m-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-macosx_10_10_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from torch>=1.2.0->sentence_transformers) (0.18.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from nltk->sentence_transformers) (7.0)\n",
      "Requirement already satisfied: six in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from packaging->transformers==3.0.2->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from packaging->transformers==3.0.2->sentence_transformers) (2.4.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->sentence_transformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->sentence_transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/piek/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers==3.0.2->sentence_transformers) (2.8)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.5.1-py3-none-any.whl size=100385 sha256=2d758bab69fafeecccc3ed285288a51eac5475c159c18cf55b5147d924dcc12d\n",
      "  Stored in directory: /Users/piek/Library/Caches/pip/wheels/8f/3e/e4/9552e3788603671ffc1c9ff56bfee684b36a88b21c05f0f91e\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.5.1 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/UKPLab/sentence-transformers\n",
    "## %pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random, glob, json, nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [\"Patient loopt wankel en bibbert.\",\n",
    "         \"Patient is moe van traplopen\",\n",
    "        \"Ze fiets elke dag naar de winkel\"]\n",
    "train_labels = ['l2', 'i2', 'i4']\n",
    "\n",
    "test_texts = [\"Patient is wankel en wiebelt.\",\n",
    "         \"Ik ben uitgeput van een rondje op straat.\",\n",
    "        \"De man gaat met de fiets naar zijn werk.\"]\n",
    "test_labels = ['l2', 'i2', 'i4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.sbert.net/docs/pretrained_models.html\n",
    "distilbert_sentence_model = SentenceTransformer ('distiluse-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_training_vectors = []\n",
    "for text in train_texts:\n",
    "    sentence_embeddings = distilbert_sentence_model.encode(text)\n",
    "    distilbert_training_vectors.append(sentence_embeddings)\n",
    "\n",
    "distilbert_test_vectors = []\n",
    "for text in test_texts:\n",
    "    sentence_embeddings = distilbert_sentence_model.encode(text)\n",
    "    distilbert_test_vectors.append(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.07514502e-02 -2.28623841e-02 -5.05056977e-03 -3.82808670e-02\n",
      " -1.12001300e-01 -4.49262150e-02  5.75736500e-02 -6.87159002e-02\n",
      "  1.93609968e-02 -1.86701789e-02 -2.62484848e-02  3.42791006e-02\n",
      " -1.45592010e-02  4.39459495e-02 -5.67155629e-02 -2.20868178e-02\n",
      " -3.27832475e-02  6.28070757e-02 -2.00314336e-02  5.59477098e-02\n",
      "  4.41969074e-02 -5.29789180e-02 -4.19642888e-02  2.49513099e-03\n",
      " -9.92450789e-02 -1.20912388e-03 -4.43195961e-02 -1.42013207e-02\n",
      "  3.63480896e-02 -3.17648239e-02 -4.06718673e-03  7.26833288e-03\n",
      " -2.83776317e-04  4.18068133e-02 -6.35279194e-02 -3.23335044e-02\n",
      " -2.00090348e-03  8.54749791e-03 -3.31182927e-02 -1.38494009e-02\n",
      " -7.02743754e-02  3.96748520e-02  5.88322384e-03  2.26890258e-02\n",
      " -2.94144060e-02 -3.28779966e-02 -6.40081391e-02 -2.10930444e-02\n",
      "  3.34102325e-02 -2.12274045e-02 -4.05326337e-02  1.17076198e-02\n",
      " -1.29251154e-02  3.60183716e-02 -4.70145158e-02  4.98163626e-02\n",
      " -6.19483031e-02 -6.03217771e-03  2.15015020e-02 -5.56116179e-02\n",
      " -2.93095149e-02 -6.19335920e-02 -5.74978488e-03 -1.35038020e-02\n",
      "  5.22327572e-02 -1.43334586e-02 -1.83904022e-02  5.26722074e-02\n",
      " -3.36783454e-02  2.99788043e-02  4.99380007e-03 -5.34000946e-03\n",
      "  2.88873129e-02 -6.39530569e-02  3.05302683e-02 -3.64462510e-02\n",
      "  1.53224142e-02  9.22705512e-03 -3.85807939e-02 -1.92223359e-02\n",
      " -2.06221305e-02 -2.03766022e-02 -1.93415526e-02 -3.50145623e-04\n",
      "  5.57093956e-02  3.42797153e-02  2.96577252e-02  6.82374015e-02\n",
      "  1.34870671e-02 -6.27744244e-03  5.12515493e-02  2.17708778e-02\n",
      "  3.54943536e-02 -4.72646579e-02  1.19042443e-02 -1.86144989e-02\n",
      " -8.99792314e-02 -1.70350168e-02 -7.16405804e-04 -1.96690932e-02\n",
      " -2.32981294e-02 -4.79455031e-02 -4.25296202e-02 -4.52481471e-02\n",
      "  1.47013022e-02 -1.02963531e-02  3.40276137e-02 -3.57243419e-02\n",
      "  1.70456730e-02  4.34067380e-03 -2.11473461e-02 -5.27340397e-02\n",
      "  5.16852774e-02 -1.52876638e-02  7.00796545e-02  2.51386524e-03\n",
      " -1.19931344e-02  3.47241014e-02 -7.29489550e-02  8.30667913e-02\n",
      "  4.83060954e-03  1.86048038e-02  5.42727113e-02  3.86026539e-02\n",
      "  4.21034172e-02 -4.34441026e-03  3.35626788e-02  2.47411802e-02\n",
      "  3.49861123e-02  1.11454045e-02  3.03688664e-02 -6.21596817e-03\n",
      " -4.91869636e-02  1.92177221e-02 -1.02795558e-02  6.35764971e-02\n",
      "  4.73483130e-02  6.47370145e-03 -7.98267033e-03  4.73262779e-02\n",
      "  7.30906278e-02 -3.68827134e-02  7.19807744e-02  1.29025532e-02\n",
      " -9.25524831e-02 -2.27565952e-02  3.87862958e-02  5.82795069e-02\n",
      " -2.10301969e-02  3.52446102e-02 -5.66277988e-02  1.48786426e-01\n",
      "  2.65361015e-02  6.19152095e-03  5.12176231e-02  5.12084439e-02\n",
      "  7.63305929e-03 -1.67741273e-02 -2.73115113e-02  6.94576697e-03\n",
      " -1.13347191e-02 -4.82380316e-02  4.17616628e-02 -7.59734632e-03\n",
      " -2.69503519e-02  1.55995181e-02 -9.26301181e-02 -5.11965305e-02\n",
      "  3.68285030e-02  1.72625333e-02  1.06217926e-02  5.41267917e-02\n",
      " -1.83248315e-02  4.88283113e-02 -6.99239597e-02  6.97652176e-02\n",
      " -2.89162491e-02  4.61154841e-02 -9.63829458e-03 -4.53101611e-03\n",
      " -8.97077285e-03  3.37836938e-03  9.42177232e-03  4.33020145e-02\n",
      "  2.48095989e-02  1.94716230e-02  5.18072098e-02  2.76482739e-02\n",
      "  8.31201822e-02 -7.11393356e-02  1.09860532e-01  7.26076867e-03\n",
      " -7.28258193e-02 -1.03152823e-04 -2.91123055e-02 -3.61586027e-02\n",
      " -5.06448224e-02  1.97678674e-02 -3.17895338e-02  2.38123480e-02\n",
      " -3.66874668e-03 -1.88953076e-02  1.33537166e-02 -4.72636595e-02\n",
      "  2.91726785e-04  2.35304292e-02 -1.22727570e-03  5.81014762e-03\n",
      "  2.05287375e-02  2.68944111e-02  2.13094559e-02  1.22862048e-02\n",
      "  5.67057636e-03 -3.97563316e-02 -6.36582971e-02  2.92452006e-03\n",
      " -1.96916610e-02  1.96930151e-02 -4.37899912e-03 -8.65846220e-03\n",
      "  6.68518022e-02 -4.42072079e-02  6.35775551e-03  1.20219784e-02\n",
      " -4.47057970e-02 -3.44844498e-02 -2.84104012e-02  1.69419609e-02\n",
      "  1.19919237e-02 -9.55632131e-04 -5.21411654e-03  5.08370772e-02\n",
      "  2.23782323e-02 -4.90311943e-02  2.98888143e-02  8.73671621e-02\n",
      " -2.11621402e-03  3.56196649e-02 -2.07805093e-02 -1.44226655e-01\n",
      "  3.71249951e-02  1.62435602e-02 -4.26624976e-02  2.11670995e-03\n",
      "  2.93097459e-04  1.54715125e-02 -1.16543891e-02  4.36368398e-03\n",
      "  3.57899740e-02  5.00567406e-02  8.64070728e-02  2.48273928e-03\n",
      " -4.83806292e-03  5.50748594e-03  3.57475951e-02 -1.25578120e-02\n",
      "  1.33331884e-02  5.51198721e-02  1.40462536e-04 -1.63334757e-02\n",
      "  2.92582829e-02 -3.67497690e-02 -3.34212817e-02 -2.60749739e-02\n",
      " -2.04374418e-02  9.93014872e-03  8.38694349e-03 -7.60991732e-03\n",
      " -7.05788359e-02 -1.31088030e-03 -7.76621625e-02  1.17625063e-02\n",
      " -4.31144470e-03 -7.12575540e-02 -4.93487492e-02 -5.73755354e-02\n",
      "  1.06859477e-02 -4.29107845e-02  2.19980720e-02  4.21415269e-02\n",
      "  6.77469792e-03  2.74763051e-02 -5.83427288e-02 -2.41886005e-02\n",
      " -6.35638908e-02 -6.20839261e-02  1.38327433e-02  2.60475501e-02\n",
      "  2.30737571e-02 -6.02461025e-02 -5.78483939e-02 -1.01606420e-03\n",
      " -2.33154874e-02 -6.20366856e-02  7.68803805e-02  1.40069332e-03\n",
      "  1.15761822e-02  1.83910830e-04 -2.63400134e-02  4.92428988e-02\n",
      "  3.13154189e-04  5.39764529e-03 -4.95354272e-02 -6.97810277e-02\n",
      "  1.30731333e-02 -1.41726257e-02 -2.69529726e-02 -2.73379423e-02\n",
      "  3.46115530e-02  3.93424295e-02  5.61850704e-02  6.65595978e-02\n",
      "  1.71013847e-02  5.25884330e-02 -5.05224895e-03 -1.36726815e-02\n",
      " -6.88675605e-03 -2.65012346e-02  1.33366510e-01 -1.83775276e-02\n",
      " -6.43579289e-03 -3.84359062e-02  9.15459991e-02 -7.91316852e-02\n",
      " -1.39147155e-02 -2.28501298e-02  1.11790849e-02  1.73146613e-02\n",
      "  8.71595088e-03 -5.24204150e-02  2.65127160e-02 -9.38619450e-02\n",
      " -6.28152341e-02  1.06371306e-02  2.02482678e-02  2.61230534e-03\n",
      "  3.82723324e-02  1.29861701e-02 -1.35038318e-02 -3.07208439e-03\n",
      "  4.82837996e-03  8.98936670e-03 -8.19232839e-04  2.02025343e-02\n",
      " -2.14864332e-02  5.93635894e-04  2.47513819e-02 -5.01521304e-02\n",
      " -1.79927666e-02 -4.47080433e-02  1.35437550e-03 -8.17827415e-03\n",
      "  3.27688409e-03 -2.13656109e-02  1.84677225e-02  1.58762950e-02\n",
      "  4.61046807e-02 -7.84714594e-02  1.92946494e-02 -1.42494859e-02\n",
      " -8.76910426e-03  4.04416323e-02  1.91695169e-02 -3.77223175e-03\n",
      "  2.26731431e-02  6.33534510e-03  7.30111590e-03 -1.85769331e-02\n",
      " -6.22441946e-03 -1.39650302e-02 -2.84192190e-02 -2.57113110e-02\n",
      " -6.88447990e-03  1.83196715e-03 -2.69066803e-02  1.95929524e-03\n",
      " -4.40781713e-02 -5.02781682e-02  5.95276132e-02  2.76009813e-02\n",
      " -1.86413489e-02 -3.07796560e-02  6.84435517e-02 -3.14415880e-02\n",
      "  7.03766719e-02  1.53004359e-02 -3.41894780e-03 -5.95706664e-02\n",
      " -1.23853795e-02 -2.78913025e-02  8.39208625e-03  1.31318932e-02\n",
      " -2.24375650e-02 -4.39808285e-03 -9.49447695e-03 -7.68274860e-03\n",
      "  1.71547644e-02  1.24412542e-02  3.62254977e-02  2.42863633e-02\n",
      " -7.07069710e-02 -9.10392497e-03  2.77049467e-03  1.06856925e-02\n",
      "  3.71757299e-02  1.49568580e-02  2.05339529e-02  2.73489002e-02\n",
      "  3.48340310e-02 -4.30105068e-02 -2.49635428e-02 -2.51632333e-02\n",
      "  3.54375914e-02 -6.50305897e-02 -1.14544500e-02  4.79954220e-02\n",
      "  2.37192120e-02  5.94143532e-02 -4.23218720e-02 -7.62782097e-02\n",
      " -1.07141212e-02  8.30500014e-03  7.54147917e-02 -1.01751670e-01\n",
      "  2.96631958e-02 -5.38972998e-03 -2.85709705e-02  9.59487911e-03\n",
      "  2.05429588e-02 -1.15966965e-02 -5.11016473e-02 -5.73836789e-02\n",
      "  1.07797896e-02 -3.45983207e-02  6.19417354e-02  3.69431935e-02\n",
      "  4.37427731e-03  3.80387045e-02 -2.88931448e-02 -2.82297144e-03\n",
      "  1.42872464e-02  9.88621041e-02 -3.22874747e-02  1.52226305e-02\n",
      " -2.09593475e-02 -4.71519791e-02 -6.14394527e-03 -4.43620533e-02\n",
      " -3.36383916e-02  7.07788300e-03  2.39371601e-03 -4.94244173e-02\n",
      "  5.64200468e-02 -4.88947034e-02 -6.03196956e-02  2.43429057e-02\n",
      "  5.52237183e-02 -1.77665800e-02  1.30344881e-02  5.01897605e-03\n",
      " -1.65549908e-02  4.72104102e-02  6.33235425e-02  1.49680637e-02\n",
      "  1.66221596e-02  3.11612971e-02  1.37106087e-02 -2.69644968e-02\n",
      "  6.22113459e-02 -5.20706512e-02 -1.32314805e-02  4.33162320e-03\n",
      "  1.37096886e-02 -1.65736899e-02 -1.24106519e-02  5.50716370e-02\n",
      " -1.20796701e-02  4.66429740e-02 -2.05804640e-03  8.12955294e-03\n",
      " -7.23760054e-02 -1.32646421e-02 -3.12032159e-02 -4.41692807e-02\n",
      "  5.33389002e-02  2.86332574e-02 -4.00628848e-03 -5.46272919e-02\n",
      "  8.31538718e-03 -3.19805779e-02  2.68716663e-02  3.84398438e-02\n",
      " -1.04593020e-02  7.18136281e-02 -2.88425088e-02 -7.48203024e-02\n",
      "  1.62724461e-02 -2.25667097e-02 -7.89900497e-03 -6.26731291e-03\n",
      "  1.99443232e-02  4.82004993e-02 -8.37149657e-03 -2.50161067e-02\n",
      "  1.55927679e-02 -5.21493889e-03 -7.43754813e-03 -3.23384739e-02\n",
      "  3.52367647e-02  4.49493602e-02  9.63322818e-03 -2.53496994e-03]\n"
     ]
    }
   ],
   "source": [
    "print(distilbert_training_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          i2       0.00      0.00      0.00         1\n",
      "          i4       0.50      1.00      0.67         1\n",
      "          l2       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.50      0.67      0.56         3\n",
      "weighted avg       0.50      0.67      0.56         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "BERT_classifier = LinearSVC(random_state=0, tol=1e-5)\n",
    "BERT_classifier.fit(distilbert_training_vectors, train_labels)\n",
    "SVM_predictions = list(BERT_classifier.predict(distilbert_test_vectors))\n",
    "predicted_test_scores= BERT_classifier.decision_function(distilbert_test_vectors) \n",
    "print(classification_report(test_labels, SVM_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying BERTJE in SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to load bertje into SentenceTransformer:\n",
    "https://repo.telematika.org/project/ukplab_sentence-transformers/\n",
    "\n",
    "I had to do the following:\n",
    "\n",
    "1. place the download of 'Bertje\" in the folder '~/.cache/torch/sentence_transformers' folder\n",
    "2. add a '  \"__version__\": \"0.1\",' field to the config.json file\n",
    "3. add an empty \"modules.json\" file:\n",
    "\n",
    "```[\n",
    "\n",
    "]```\n",
    "\n",
    "With these changes I can load BERTJE in SentenceTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "localBertje = '/Users/piek/.cache/torch/sentence_transformers/wietsedv.bert-base-ductch-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_model = SentenceTransformer(localBertje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1975c89711cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbertje_training_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_transformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbertje_training_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, is_pretokenized, device, num_workers)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_sorted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_sorted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bertje_training_vectors = []\n",
    "for text in train_texts:\n",
    "    sentence_embeddings = sentence_transformer_model.encode(text)\n",
    "    bertje_training_vectors.append(sentence_embeddings)\n",
    "\n",
    "bertje_test_vectors = []\n",
    "for text in test_texts:\n",
    "    sentence_embeddings = sentence_transformer_model.encode(text)\n",
    "    bertje_test_vectors.append(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_classifier = LinearSVC(random_state=0, tol=1e-5)\n",
    "BERT_classifier.fit(bertje_training_vectors, train_labels)\n",
    "SVM_predictions = list(BERT_classifier.predict(bertje_test_vectors))\n",
    "predicted_test_scores= BERT_classifier.decision_function(bertje_test_vectors) \n",
    "print(classification_report(bertje_test_vectors, SVM_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245M/245M [00:21<00:00, 11.6MB/s] \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'A man is eating pasta.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'The baby is carried by the woman',\n",
    "          'A man is riding a horse.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.',\n",
    "          'A cheetah is running behind its prey.',\n",
    "          'A cheetah chases prey on across a field.']\n",
    "\n",
    "corpus_embeddings = embedder.encode(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2 2 4 4 3 3 1 1]\n",
      "Cluster  1\n",
      "['A man is eating food.', 'A man is eating a piece of bread.', 'A man is eating pasta.']\n",
      "\n",
      "Cluster  2\n",
      "['A cheetah is running behind its prey.', 'A cheetah chases prey on across a field.']\n",
      "\n",
      "Cluster  3\n",
      "['The girl is carrying a baby.', 'The baby is carried by the woman']\n",
      "\n",
      "Cluster  4\n",
      "['A monkey is playing drums.', 'Someone in a gorilla costume is playing a set of drums.']\n",
      "\n",
      "Cluster  5\n",
      "['A man is riding a horse.', 'A man is riding a white horse on an enclosed ground.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 5\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "print(cluster_assignment)\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A man is eating pasta.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating pasta. (Score: 1.0000)\n",
      "A man is eating food. (Score: 0.5777)\n",
      "A man is eating a piece of bread. (Score: 0.4986)\n",
      "A man is riding a horse. (Score: 0.1581)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1474)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Someone in a gorilla costume is playing a set of drums. (Score: 1.0000)\n",
      "A monkey is playing drums. (Score: 0.6435)\n",
      "A man is eating a piece of bread. (Score: 0.1719)\n",
      "A man is eating food. (Score: 0.1240)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.0706)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah chases prey on across a field. (Score: 1.0000)\n",
      "A cheetah is running behind its prey. (Score: 0.7769)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.2485)\n",
      "A man is riding a horse. (Score: 0.2116)\n",
      "A monkey is playing drums. (Score: 0.1820)\n"
     ]
    }
   ],
   "source": [
    "# Query sentences:\n",
    "queries = ['A man is eating pasta.', 'Someone in a gorilla costume is playing a set of drums.', 'A cheetah chases prey on across a field.']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
