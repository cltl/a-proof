{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following:\n",
    "\n",
    "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "\n",
    "Credits:\n",
    "\n",
    "Chris McCormick and Nick Ryan. (2019, May 14). BERT Word Embeddings Tutorial. Retrieved from http://www.mccormickml.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [\"Patient loopt wankel en bibbert.\",\n",
    "         \"Patient is moe van traplopen\",\n",
    "        \"Ze fiets elke dag naar de winkel\"]\n",
    "train_labels = ['l2', 'i2', 'i4']\n",
    "\n",
    "test_texts = [\"Patient is wankel en wiebelt.\",\n",
    "         \"Ik ben uitgeput van een rondje op straat.\",\n",
    "        \"De man gaat met de fiets naar zijn werk.\"]\n",
    "test_labels = ['l2', 'i2', 'i4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertje='wietsedv/bert-base-dutch-cased'\n",
    "#bertje='bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30000, 768, padding_idx=3)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "bertje_tokenizer = BertTokenizer.from_pretrained(bertje)\n",
    "bertje_model = BertModel.from_pretrained(bertje, output_hidden_states = True) # Whether the model returns all hidden-states.)\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "bertje_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['levensverhaal',\n",
       " 'levenswijze',\n",
       " 'lever',\n",
       " 'leverancier',\n",
       " 'leveranciers',\n",
       " 'leverbaar',\n",
       " 'leverde',\n",
       " 'leveren',\n",
       " 'levering',\n",
       " 'levert',\n",
       " 'lezen',\n",
       " 'lezer',\n",
       " 'lezers',\n",
       " 'lezing',\n",
       " 'lezingen',\n",
       " 'li',\n",
       " 'lib',\n",
       " 'libellen',\n",
       " 'liberaal',\n",
       " 'liberale']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking out BERTje's vocabulary\n",
    "list(bertje_tokenizer.vocab.keys())[15000:15020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marked trained text[0] [CLS] Patient loopt wankel en bibbert. [SEP]\n",
      "<class 'str'>\n",
      "marked text [CLS] Patient loopt wankel en bibbert. [SEP]\n",
      "<class 'str'>\n",
      "tokenized text {'input_ids': tensor([[    1,     1,  5512, 26105, 15177, 22227, 11281,  9529,   132,    13,\n",
      "             2,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "token ids [0, 0, 0]\n",
      "segment ids [1, 1, 1]\n",
      "input_ids         0\n",
      "token_type_ids      0\n",
      "attention_mask      0\n"
     ]
    }
   ],
   "source": [
    "#### note the tokenizer is called differently than the documented examples in:\n",
    "## https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "## where it says: \n",
    "\n",
    "#>>> tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#>>> model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "\n",
    "#>>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "#>>> outputs = model(**inputs)\n",
    "\n",
    "#>>> last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "marked_text = '[CLS] '+\"Patient loopt wankel en bibbert.\"+ ' [SEP]'\n",
    "tokenized_text = bertje_tokenizer.tokenize(marked_train_text[0])\n",
    "tokenized_text = tokenizer(marked_text, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "token_ids = bertje_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segment_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print('marked trained text[0]', marked_train_text[0])\n",
    "print(type(marked_train_text[0]))\n",
    "print('marked text', marked_text)\n",
    "print(type(marked_text))\n",
    "print('tokenized text', tokenized_text)\n",
    "print('token ids', token_ids)\n",
    "print('segment ids', segment_ids)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, token_ids):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([token_ids])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(tokens_tensor.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,     1,  5512, 26105, 15177, 22227, 11281,  9529,   132,    13,\n",
      "             2,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "    print (tokenized_text)\n",
    "    #outputs = bertje_model(tokens_tensor, segments_tensors)\n",
    "    outputs = bertje_model(**tokenized_text)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.7453,  0.3119,  1.2152,  ...,  0.5540,  1.7434,  0.2024],\n",
      "         [-0.8552,  0.1490,  0.8565,  ...,  0.6793,  1.7598,  0.2586],\n",
      "         [ 1.7831,  1.0930,  0.3459,  ...,  0.5615, -0.3803,  0.3299],\n",
      "         ...,\n",
      "         [ 0.3265, -0.0293,  0.4527,  ...,  0.3535, -0.4330, -0.8264],\n",
      "         [ 0.4432,  0.0589, -0.6798,  ...,  1.1498,  0.4757,  0.4151],\n",
      "         [ 0.1965, -0.3239, -0.7725,  ...,  1.2099,  0.3377,  0.3097]]]), tensor([[[-0.0350,  0.7342,  0.8716,  ...,  0.2325,  1.6016, -0.1824],\n",
      "         [-0.2450,  0.4725,  0.7208,  ...,  0.1403,  1.4009, -0.1233],\n",
      "         [ 2.0377,  1.2377, -0.0117,  ...,  0.4454,  0.0245,  0.4253],\n",
      "         ...,\n",
      "         [ 0.5513, -0.3122,  0.3779,  ..., -0.0190,  0.3434, -0.7196],\n",
      "         [ 0.4867,  0.0281, -0.4082,  ...,  0.2102,  0.6290,  0.2026],\n",
      "         [ 0.3889, -0.1795, -0.4462,  ...,  0.2124,  0.5301,  0.1593]]]), tensor([[[-0.1514,  0.7004,  0.3314,  ...,  0.3998,  1.2812,  0.1254],\n",
      "         [-0.1171,  0.4879,  0.1425,  ...,  0.4394,  1.1023,  0.0607],\n",
      "         [ 1.9229,  1.5765, -0.2407,  ...,  0.7647,  0.0442,  0.4702],\n",
      "         ...,\n",
      "         [ 0.6297, -0.3728,  0.1223,  ...,  0.2918,  0.3166, -0.4534],\n",
      "         [ 0.6180, -0.0317, -0.3663,  ...,  0.3446,  0.4067,  0.2298],\n",
      "         [ 0.5106, -0.2226, -0.4579,  ...,  0.3208,  0.3783,  0.2010]]]), tensor([[[-0.0109,  0.5505,  0.1177,  ...,  0.1201,  0.5246, -0.2059],\n",
      "         [ 0.0518,  0.1733, -0.0178,  ..., -0.0487,  0.4041, -0.1883],\n",
      "         [ 1.6177,  1.2376, -0.1009,  ...,  0.4842,  0.4123,  0.9391],\n",
      "         ...,\n",
      "         [ 0.6878, -0.3454,  0.2310,  ...,  0.1624,  0.1602, -0.4002],\n",
      "         [ 0.4115, -0.1811, -0.5577,  ...,  0.1101,  0.1619,  0.1327],\n",
      "         [ 0.3204, -0.3076, -0.6829,  ...,  0.0865,  0.1419,  0.1693]]]), tensor([[[-5.1745e-01,  3.4026e-01,  2.6911e-01,  ...,  3.6794e-01,\n",
      "           8.8512e-02,  1.5068e-02],\n",
      "         [-2.9237e-02,  7.2543e-02, -1.8934e-01,  ...,  9.2072e-02,\n",
      "          -4.0424e-02, -4.0898e-02],\n",
      "         [ 1.1981e+00,  9.5975e-01, -1.7431e-01,  ...,  5.9669e-01,\n",
      "           6.9058e-01,  1.3795e+00],\n",
      "         ...,\n",
      "         [ 7.2216e-01, -3.5477e-01,  2.1103e-01,  ...,  1.1759e-01,\n",
      "           6.1506e-02, -1.8243e-01],\n",
      "         [ 3.5366e-01, -3.0086e-01, -6.2689e-01,  ...,  7.7290e-02,\n",
      "           1.3065e-03,  3.6631e-01],\n",
      "         [ 2.4422e-01, -4.0914e-01, -6.7097e-01,  ...,  8.3417e-02,\n",
      "          -1.4565e-02,  3.8447e-01]]]), tensor([[[-0.1764,  0.0875,  0.2060,  ...,  0.4571,  0.1504,  0.2308],\n",
      "         [ 0.0064, -0.0723, -0.3034,  ..., -0.0313, -0.1538,  0.1607],\n",
      "         [ 0.9412,  0.8767, -0.5121,  ...,  0.8778,  0.0890,  0.2984],\n",
      "         ...,\n",
      "         [ 0.4683, -0.5643, -0.0282,  ..., -0.1985,  0.1522,  0.0444],\n",
      "         [ 0.1923, -0.5741, -0.5985,  ...,  0.0551, -0.0697,  0.5943],\n",
      "         [ 0.1543, -0.6413, -0.6176,  ...,  0.0732, -0.0763,  0.5689]]]), tensor([[[ 0.0669, -0.1386,  0.4949,  ...,  0.3089,  0.1550,  0.4409],\n",
      "         [ 0.2698, -0.3493, -0.5903,  ..., -0.0486,  0.2691,  0.1683],\n",
      "         [ 0.9876,  0.4943, -0.4860,  ...,  0.5039,  0.2940,  0.0936],\n",
      "         ...,\n",
      "         [ 0.4927, -0.5695, -0.1861,  ..., -0.1602,  0.1091, -0.0291],\n",
      "         [-0.1986, -0.3758, -0.4512,  ...,  0.1119, -0.1146,  0.4943],\n",
      "         [-0.2217, -0.4028, -0.4168,  ...,  0.1205, -0.0731,  0.4074]]]), tensor([[[-0.0123, -0.3893,  0.2401,  ...,  0.3041, -0.4005,  0.3927],\n",
      "         [ 0.3260, -0.4029, -0.5611,  ...,  0.1174, -0.1912,  0.1663],\n",
      "         [ 1.0706,  0.2017, -0.6644,  ...,  0.4728, -0.1310, -0.3215],\n",
      "         ...,\n",
      "         [ 0.3325, -0.6835, -0.1630,  ...,  0.1454,  0.0519,  0.2266],\n",
      "         [-0.4250, -0.5002, -0.4115,  ...,  0.3742,  0.0353,  0.6148],\n",
      "         [-0.4179, -0.5241, -0.3977,  ...,  0.3600,  0.0303,  0.5045]]]), tensor([[[-0.2456, -0.7696,  0.0045,  ...,  0.6337, -0.5022,  0.9712],\n",
      "         [ 0.3425, -0.4856, -0.6899,  ..., -0.2569, -0.4226,  0.3065],\n",
      "         [ 1.0617,  0.4000, -1.2463,  ...,  0.5895, -0.0700,  0.2980],\n",
      "         ...,\n",
      "         [ 0.1242, -0.3764, -0.0257,  ...,  0.1997,  0.1358,  0.5472],\n",
      "         [-0.4386, -0.0727, -0.0550,  ...,  0.4827, -0.0492,  0.7537],\n",
      "         [-0.4392, -0.0970, -0.0241,  ...,  0.4367, -0.0691,  0.6533]]]), tensor([[[-0.1741, -0.6922,  0.1835,  ...,  0.1563, -0.3412,  1.0910],\n",
      "         [ 0.3614, -0.3608, -1.2446,  ..., -0.6983, -0.4197,  0.2127],\n",
      "         [ 0.6749,  0.4048, -1.0420,  ..., -0.0138, -0.0361,  0.3911],\n",
      "         ...,\n",
      "         [ 0.1237,  0.0094, -0.1011,  ...,  0.1466,  0.0149,  0.2018],\n",
      "         [-0.0756, -0.1115,  0.1446,  ...,  0.1163,  0.1029,  0.6774],\n",
      "         [-0.1031, -0.1371,  0.1083,  ...,  0.0847,  0.1115,  0.5825]]]), tensor([[[ 0.0808, -0.9208,  0.3477,  ...,  0.1384, -0.2289,  0.8305],\n",
      "         [ 0.3602,  0.1174, -0.7666,  ..., -1.0301, -0.7939,  0.3312],\n",
      "         [ 0.4594,  0.6046, -0.9521,  ..., -0.1013, -0.3297,  0.5753],\n",
      "         ...,\n",
      "         [ 0.0584,  0.1349,  0.0055,  ...,  0.1552,  0.0465,  0.0659],\n",
      "         [ 0.1199, -0.1027,  0.2170,  ...,  0.3877, -0.0436,  0.2354],\n",
      "         [ 0.0511, -0.0083,  0.1329,  ...,  0.3073,  0.0042,  0.1434]]]), tensor([[[-0.2266, -0.6816, -0.1053,  ...,  0.0882, -0.0816,  0.6543],\n",
      "         [-0.0229,  0.4511, -0.8779,  ..., -0.9099, -0.3280,  0.1776],\n",
      "         [ 0.6052,  0.6842, -0.6055,  ...,  0.1064, -0.2689,  0.5835],\n",
      "         ...,\n",
      "         [-0.0094,  0.0926, -0.0269,  ...,  0.0806,  0.0465,  0.0444],\n",
      "         [ 0.0180,  0.0745, -0.0292,  ...,  0.1032,  0.0098,  0.0567],\n",
      "         [-0.0024,  0.0840, -0.0267,  ...,  0.0926,  0.0256,  0.0460]]]), tensor([[[-0.2490, -0.4836, -0.2426,  ...,  0.0156,  0.1098,  0.2735],\n",
      "         [-0.2728,  0.4996, -0.6483,  ..., -0.9233, -0.2651, -0.0498],\n",
      "         [ 0.5162,  0.4568, -0.3884,  ...,  0.2867, -0.2985,  0.4380],\n",
      "         ...,\n",
      "         [ 0.8433,  0.9874,  0.1377,  ..., -1.0028,  0.0280,  0.7774],\n",
      "         [ 0.7877,  0.9939,  0.1724,  ..., -0.8987,  0.0042,  0.8173],\n",
      "         [ 0.8107,  0.9829,  0.1586,  ..., -0.9450,  0.0158,  0.8069]]]))\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 12\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type of hidden_states:  <class 'tuple'>\n",
      "Tensor shape for each layer:  torch.Size([1, 12, 768])\n"
     ]
    }
   ],
   "source": [
    "# `hidden_states` is a Python list.\n",
    "print('      Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 12, 768])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 12, 768])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 13, 768])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1. so that the first element are the tokens, 2nd are the layers and 3rd are the dimensions\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hidden_states_to_token_embeddings(hidden_states):\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    return token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors\n",
    "To give you some examples, let’s create word vectors two ways.\n",
    "\n",
    "First, let’s concatenate the last four layers, giving us a single word vector per token. Each vector will have length 4 x 768 = 3,072."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 12 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative method, let’s try creating the word vectors by summing together the last four layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 12 x 768\n"
     ]
    }
   ],
   "source": [
    "#Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Vectors\n",
    "To get a single vector for our entire sentence we have multiple application-dependent strategies, but a simple approach is to average the second to last hiden layer of each token producing a single 768 length vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying a batch input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_text (texts):\n",
    "    marked_text_list = []\n",
    "    for text in texts:\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        marked_text_list.append(marked_text)\n",
    "    return marked_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_train_texts = mark_text(train_texts)\n",
    "marked_test_texts = mark_text(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_tokens(texts, bertje_tokenizer, verbose=0):\n",
    "    tokens = []\n",
    "    for text in texts:\n",
    "        #tokenized_text = bertje_tokenizer.tokenize([text])\n",
    "        tokenized_text = tokenizer(text, return_tensors=\"pt\")\n",
    "        if verbose:\n",
    "            print('tokenized text', tokenized_text)\n",
    "        tokens.append(tokenized_text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed\n",
    "def get_sentence_token_ids(tokenized_texts, bertje_tokenizer, verbose=0):\n",
    "    token_ids = []\n",
    "    for tokenized_text in tokenized_texts:\n",
    "        token_ids = bertje_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        if verbose:\n",
    "            print('token ids', token_ids)\n",
    "        token_ids.append(token_ids)\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed\n",
    "def get_segment_ids(tokenized_texts, verbose=0):\n",
    "    segment_ids = []\n",
    "    for tokenized_text in tokenized_texts:\n",
    "        segment_ids = [1] * len(tokenized_text)\n",
    "        if verbose:\n",
    "            print('segment ids', segment_ids)\n",
    "        segment_ids.append(segment_ids)\n",
    "    return segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized text {'input_ids': tensor([[    1,     1,  5512, 26105, 15177, 22227, 11281,  9529,   132,    13,\n",
      "             2,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tokenized text {'input_ids': tensor([[    1,     1,  5512, 26105, 13903, 15723, 20722, 20321, 26954,     2,\n",
      "             2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tokenized text {'input_ids': tensor([[    1,     1,  7769, 11572, 11262, 10494, 15892, 10537, 22500,     2,\n",
      "             2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_texts = get_sentence_tokens(marked_train_texts, bertje_tokenizer, 1)\n",
    "#token_ids_train_text = get_sentence_token_ids(tokenized_train_texts, bertje_tokenizer, 0)\n",
    "#segment_ids_train_text = get_segment_ids(tokenized_train_texts)\n",
    "\n",
    "tokenized_test_texts = get_sentence_tokens(marked_test_texts, bertje_tokenizer, 0)\n",
    "#token_ids_test_text = get_sentence_token_ids(tokenized_test_texts, bertje_tokenizer, 0)\n",
    "#segment_ids_test_text = get_segment_ids(tokenized_test_texts, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.no_grad tells PyTorch not to construct the compute graph during this forward pass\n",
    "#(since we won’t be running backprop here)–this just reduces memory consumption and \n",
    "# speeds things up a little.\n",
    "\n",
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers.\n",
    "\n",
    "def get_hidden_states_from_tokenized_text (tokenized_texts, model):\n",
    "    hidden_states_list =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tokenized_text in tokenized_texts:\n",
    "            print(type(tokenized_text))\n",
    "            #print (tokenized_text)\n",
    "            outputs = bertje_model(**tokenized_text)\n",
    "            # Evaluating the model will return a different number of objects based on \n",
    "            # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "            # becase we set `output_hidden_states = True`, the third item will be the \n",
    "            # hidden states from all layers. See the documentation for more details:\n",
    "            # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "            hidden_states = outputs[2]\n",
    "            hidden_states_list.append(hidden_states)\n",
    "    return hidden_states_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating sentence vectors for input\n",
    "\n",
    "def get_sentence_embeddings (tokenized_text, model):\n",
    "    sentence_embeddings = []\n",
    "    hidden_states_list = get_hidden_states_from_tokenized_text(tokenized_text, bertje_model)\n",
    "\n",
    "\n",
    "    for hidden_states in hidden_states_list:\n",
    "        convert_hidden_states_to_token_embeddings(hidden_states)\n",
    "        # `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "        # `token_vecs` is a tensor with shape [22 x 768]\n",
    "        token_vecs = hidden_states[-2][0]  ### change to -4 to get the last 4 layers as used for NERC\n",
    "\n",
    "        # Calculate the average of all 22 token vectors.\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        sentence_embeddings.append(np.array(sentence_embedding))\n",
    "    return sentence_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "bertje_training_vectors = get_sentence_embeddings(tokenized_train_texts, bertje_model)\n",
    "bertje_test_vectors = get_sentence_embeddings(tokenized_test_texts, bertje_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.26854280e-01  3.64366889e-01 -2.64939189e-01 -2.16569901e-02\n",
      "  4.23036218e-01 -3.06041837e-01  7.25228250e-01 -1.34269550e-01\n",
      "  1.27096102e-01  1.61743760e-01  4.45829965e-02 -4.70153898e-01\n",
      " -3.71987037e-02 -2.58300692e-01  2.84657449e-01  1.02166511e-01\n",
      "  3.29507142e-01 -3.30159180e-02 -4.24469709e-02  1.92498222e-01\n",
      "  2.21560910e-01 -1.77030399e-01 -2.20597863e-01  6.96013123e-02\n",
      "  1.62168499e-02 -2.80006558e-01 -2.88313478e-02  2.14737728e-01\n",
      "  9.42061841e-02 -2.29923546e-01  3.07494015e-01 -2.76333988e-02\n",
      "  3.78727436e-01 -9.70472302e-03  9.25650299e-02 -3.06998361e-02\n",
      "  1.50071934e-01  1.40077965e-02  6.63034767e-02 -2.60442317e-01\n",
      "  1.27322808e-01  8.55716541e-02  2.44976371e-03  1.07875913e-01\n",
      " -8.77190009e-02  7.83961639e-02 -1.42496660e-01 -2.05088541e-01\n",
      "  3.85075003e-01 -1.66923106e-01  3.49197626e-01  2.90625125e-01\n",
      "  2.15229526e-01  3.59508425e-01  3.64061266e-01  1.26831690e-02\n",
      " -2.75044858e-01  2.63085157e-01  2.10178673e-01  1.62515894e-01\n",
      " -1.90799654e-01  2.55870730e-01  1.68321952e-01  1.50928274e-01\n",
      "  3.98366183e-01 -2.36756131e-01 -3.97443384e-01 -2.93634057e-01\n",
      " -1.32408053e-01 -1.50991395e-01  2.70864755e-01  3.81652974e-02\n",
      "  6.41432479e-02  1.99387856e-02 -3.19572777e-01 -2.11393282e-01\n",
      "  3.05237204e-01 -1.23060083e+00  3.53341728e-01 -2.46601328e-01\n",
      " -1.95461258e-01 -1.72250047e-01 -4.02846783e-01  2.08161280e-01\n",
      " -2.06476986e-01  7.04917237e-02  9.80983153e-02  8.30456838e-02\n",
      " -3.21394980e-01  9.94373932e-02 -3.29597779e-02  5.41547425e-02\n",
      "  1.06153702e-02  2.46921703e-01 -4.85118240e-01 -2.35482737e-01\n",
      "  4.87923890e-01 -4.58711237e-02  3.42601031e-01 -1.17229961e-01\n",
      "  4.00997043e-01  5.96652366e-02 -2.52387729e-02  1.97066799e-01\n",
      " -3.12473774e-01 -2.93998141e-02 -1.07198201e-01 -1.99767813e-01\n",
      " -8.53777006e-02  4.43855911e-01 -3.13949615e-01 -3.88780013e-02\n",
      "  1.72011510e-01  1.13697276e-02  2.89898187e-01 -1.90318540e-01\n",
      " -1.08494237e-02 -3.32223564e-01  7.50142559e-02 -4.11824994e-02\n",
      " -1.37229517e-01  7.13326707e-02  5.62259704e-02  4.08021331e-01\n",
      " -4.20834631e-01 -8.72563291e-03 -1.05291545e-01 -2.37334445e-01\n",
      " -6.54425025e-02  3.12749855e-02 -5.44844925e-01 -4.72159199e-02\n",
      " -4.05908108e-01  1.50516346e-01 -3.54104931e-03  2.18362659e-02\n",
      "  1.35486528e-01  1.74007073e-01 -2.58939043e-02 -6.28325790e-02\n",
      "  1.46267980e-01 -3.75691861e-01  2.57698119e-01  1.13267481e-01\n",
      "  4.00894910e-01 -2.95056462e-01  1.64565101e-01 -1.02051318e+00\n",
      " -2.57327497e-01  2.12119743e-01  3.24680775e-01  2.10923955e-01\n",
      "  1.58859268e-01  6.57158867e-02  3.07015866e-01  5.95788181e-01\n",
      "  5.51725864e-01  5.66932976e-01  2.54404038e-01  1.95367530e-01\n",
      "  2.48221442e-01 -2.14822039e-01 -1.53193250e-01 -3.79360467e-02\n",
      " -7.95714140e-01  4.31853347e-02  6.18578903e-02  6.77246377e-02\n",
      "  8.48984495e-02 -3.89234051e-02 -4.15871739e-01 -1.73773155e-01\n",
      " -4.13906090e-02  4.81065601e-01 -2.79672414e-01 -1.11141719e-01\n",
      "  1.32646253e-02  2.59557944e-02 -1.59246668e-01  6.61915466e-02\n",
      "  8.95174816e-02 -6.06544875e-02 -2.63055891e-01 -2.52117659e-03\n",
      " -1.15077421e-02 -3.50601263e-02 -4.28982705e-01  1.70251474e-01\n",
      " -3.01639289e-01 -6.82382062e-02  1.21413678e-01 -2.42354453e-01\n",
      "  3.19697820e-02 -2.32109144e-01  8.52470174e-02 -6.42060116e-02\n",
      " -3.10236514e-01  4.53141332e-02  3.45661312e-01 -6.35890782e-01\n",
      "  1.93429187e-01  3.46464396e-01  2.98034400e-01  2.95743912e-01\n",
      " -2.76463985e-01  2.35152077e-02  8.50555375e-02 -4.73763347e-01\n",
      "  8.04340318e-02 -3.31113003e-02  1.21900700e-01 -2.55188018e-01\n",
      " -2.19637647e-01 -2.81015664e-01 -4.81555760e-02  9.60707590e-02\n",
      " -3.05593640e-01 -3.33380222e-01 -7.55019262e-02 -5.72107127e-03\n",
      "  3.97175193e-01 -6.31374344e-02  2.62551364e-02  7.19876230e-01\n",
      "  1.42968535e-01 -2.04088524e-01 -7.73873255e-02 -3.71308237e-01\n",
      " -2.14785770e-01  1.36839792e-01 -1.47548718e-02  4.49894786e-01\n",
      "  1.71348657e-02  9.85459164e-02 -5.11664569e-01 -6.55791759e-02\n",
      "  2.20877066e-01 -2.92018205e-01 -3.39235328e-02 -5.17084539e-01\n",
      " -2.85252929e-02  2.35904336e-01  1.28533199e-01  7.43388087e-02\n",
      " -5.16212024e-02  2.32904717e-01  1.03471704e-01  7.72711858e-02\n",
      " -1.25977114e-01 -3.23406070e-01  6.08702004e-01  2.42089495e-01\n",
      " -1.65643319e-01  1.38649777e-01 -2.79315203e-01 -8.85110870e-02\n",
      " -4.02282357e-01  9.86848772e-02  1.03779495e-01 -1.38429880e-01\n",
      " -2.20764711e-01  1.47336513e-01 -2.63023704e-01 -5.99198230e-02\n",
      " -8.39308500e-02 -1.25404194e-01 -2.63175696e-01 -2.57481188e-01\n",
      "  3.16486090e-01 -1.94142256e-02  2.64556468e-01 -4.06749338e-01\n",
      " -6.45829663e-02  5.35198711e-02 -5.14635503e-01  1.39152231e-02\n",
      " -1.58866301e-01 -2.22888172e-01 -2.25572452e-01  4.54800837e-02\n",
      " -3.37380052e-01 -2.56588429e-01 -2.03068122e-01 -2.00752672e-02\n",
      "  1.27312660e-01 -1.25799581e-01  5.28200679e-02 -3.68297607e-01\n",
      "  1.73242852e-01 -1.43516123e-01 -2.37209246e-01 -6.23952188e-02\n",
      "  1.45150140e-01  4.70177025e-01 -5.41451201e-03  1.92269430e-01\n",
      "  9.47377458e-02 -1.62622273e-01 -3.34287554e-01 -8.29783604e-02\n",
      "  1.32030025e-01  1.52273789e-01  2.39161402e-03 -9.19425115e-02\n",
      "  1.64978847e-01  1.53252333e-02 -3.35448384e-01 -2.02202156e-01\n",
      "  1.87461793e-01  4.31407942e-03 -4.66213018e-01  4.26960021e-01\n",
      " -1.41587958e-01  3.59880060e-01 -1.06028132e-01 -1.95580900e-01\n",
      "  4.94392365e-01  1.20736711e-01  4.73062992e-02 -2.92739600e-01\n",
      "  2.82059371e-01  1.42721578e-01  1.68411750e-02 -3.34393889e-01\n",
      " -3.41617800e-02 -3.04716498e-01 -1.87234543e-02  3.78847569e-01\n",
      " -1.25032291e-01  1.12531424e-01 -5.48751988e-02 -3.80766243e-02\n",
      "  1.50877193e-01  3.23122531e-01  1.42950878e-01  1.16166346e-01\n",
      "  3.49950157e-02 -2.20833600e-01  1.66743502e-01  1.28588840e-01\n",
      " -1.15095405e-02  1.59529924e-01 -1.86569110e-01  8.24540108e-03\n",
      "  3.36735338e-01  2.30355993e-01 -4.55719680e-02  1.95515811e-01\n",
      "  2.97885567e-01 -4.50792126e-02  2.10995093e-01  2.33138368e-01\n",
      " -4.38152283e-01  7.46550038e-02 -3.24349031e-02 -2.19785973e-01\n",
      "  1.87013131e-02 -1.58108845e-01 -1.68981254e-01  1.57134041e-01\n",
      " -1.19558401e-01  6.74601495e-02  3.56401578e-02  1.05791658e-01\n",
      " -2.50393838e-01 -2.32734993e-01 -1.00675086e-02  8.85537534e-04\n",
      "  6.63497820e-02 -1.69860616e-01  7.88417682e-02 -3.54765385e-01\n",
      "  1.37235388e-01  2.99008563e-03 -6.50174776e-03 -1.69643179e-01\n",
      " -7.16480792e-01  1.19588703e-01  4.27430063e-01  3.14285100e-01\n",
      "  8.69704112e-02  1.69064403e-01 -5.05774654e-03  6.66143000e-01\n",
      "  2.60606825e-01 -4.17009145e-01 -1.10713102e-01  1.53969333e-01\n",
      " -8.97680596e-02  2.89534897e-01 -2.23094687e-01 -2.87759930e-01\n",
      "  1.27573922e-01  4.53306101e-02  2.11610615e-01  6.01382971e-01\n",
      " -3.92853588e-01  1.53833464e-01 -7.73945600e-02 -1.89678922e-01\n",
      " -1.29407749e-01  2.05539331e-01  1.63874611e-01  1.60632759e-01\n",
      "  5.73272645e-01  2.22228765e-01 -1.01500489e-02 -7.26237819e-02\n",
      " -8.43559727e-02 -2.65216947e-01 -1.95600882e-01  6.28322586e-02\n",
      "  4.04176235e-01 -1.84586402e-02 -8.54755640e-02  2.85942733e-01\n",
      "  2.08733365e-01 -2.20257297e-01  4.84399498e-02  1.89181879e-01\n",
      " -1.48758784e-01 -2.04466268e-01 -2.20427141e-01 -2.90916473e-01\n",
      " -5.60185276e-02  2.17200890e-01  6.75242171e-02 -7.08040074e-02\n",
      " -3.29707325e-01  1.26764784e-02 -3.53352815e-01  1.71624437e-01\n",
      " -5.04740894e-01 -3.87150556e-01  3.28601837e-01  2.63550729e-01\n",
      "  3.63851637e-01 -5.10124005e-02 -5.97793013e-02 -3.36347222e-01\n",
      "  2.08110332e-01 -1.06802978e-01  7.71435574e-02  4.00252081e-02\n",
      " -4.33603734e-01 -1.60210326e-01 -3.10090810e-01  3.25252265e-01\n",
      " -1.69753030e-01  3.72552276e-01  2.53601104e-01  4.60507758e-02\n",
      " -1.84642598e-01 -2.03278497e-01 -6.19878829e-01 -6.14245355e-01\n",
      " -4.05781627e-01 -2.38548353e-01  1.49705812e-01 -7.13815212e-01\n",
      "  1.18136518e-02  1.78021416e-01  2.54055887e-01  1.18045859e-01\n",
      " -2.96958759e-02  3.92789632e-01  1.14999153e-01  1.62564680e-01\n",
      "  2.85462260e-01 -8.05924609e-02 -4.35970694e-01 -6.76972046e-02\n",
      " -2.09888384e-01 -6.36214554e-01  2.13116631e-01  1.31574661e-01\n",
      " -1.06035471e-01  1.87618017e-01 -2.15981558e-01  8.79454195e-01\n",
      " -7.55701140e-02 -8.01866055e-02  1.24865800e-01 -4.78207581e-02\n",
      " -1.94304779e-01  1.88309904e-02 -3.34971577e-01  1.00165361e-03\n",
      " -2.09135249e-01  5.10479808e-01 -1.59043476e-01  3.04805607e-01\n",
      " -3.09967190e-01 -5.09529561e-02 -3.06415379e-01 -5.27399480e-01\n",
      " -2.39786163e-01  1.72777519e-01  1.69030115e-01  2.32637331e-01\n",
      " -8.20448622e-02 -6.05746545e-02  4.88237351e-01  3.66405249e-01\n",
      " -1.91974640e-01 -4.88836795e-01 -6.48704290e-01  6.63740039e-02\n",
      "  1.39210848e-02 -1.37480900e-01 -5.88189699e-02  3.15854877e-01\n",
      " -2.01431334e-01 -2.07976833e-01 -3.93222809e-01  3.77625912e-01\n",
      " -1.39362827e-01 -1.55106902e-01 -9.73282680e-02  5.60051382e-01\n",
      "  2.61001945e-01  2.16982797e-01  1.39946386e-01 -9.04575214e-02\n",
      "  1.23259008e-01 -1.79449126e-01 -1.51594907e-01 -4.49880481e-01\n",
      "  1.43736303e-01 -1.24077164e-01  3.01216930e-01  6.84041977e-02\n",
      "  1.62439048e-02 -6.47327825e-02 -2.38288417e-01  3.71052265e-01\n",
      "  7.44952485e-02 -2.33834162e-01  8.99330713e-03 -3.67348045e-01\n",
      " -1.10581219e-01 -1.68197993e-02 -9.21153948e-02 -1.63413957e-01\n",
      " -1.50162965e-01  5.13892882e-02 -2.72354454e-01  2.50819940e-02\n",
      " -2.84901470e-01  7.71351159e-03  2.22599819e-01 -1.19162463e-01\n",
      "  1.55476943e-01 -2.93055903e-02  4.20324713e-01  1.57518730e-01\n",
      " -3.40804905e-01 -6.15408421e-02 -3.12463462e-01  1.10813670e-01\n",
      " -3.26341778e-01 -4.08068439e-03 -1.32877052e-01 -1.11826830e-01\n",
      " -7.72519335e-02  2.43874192e-01 -1.99219391e-01  8.86423513e-02\n",
      " -2.85816491e-01 -5.10298312e-02  1.10201977e-01 -3.84007931e-01\n",
      " -4.22257334e-01 -1.08297296e-01  5.85126765e-02 -1.64820179e-01\n",
      "  1.99399903e-01  4.34263915e-01 -2.37280115e-01  4.37009454e-01\n",
      "  1.74203262e-01 -4.18470293e-01  4.42201793e-02 -4.88369204e-02\n",
      " -5.71423709e-01 -3.79928261e-01 -9.21614990e-02 -6.54109493e-02\n",
      "  5.37782870e-02 -1.05537005e-01  2.79605955e-01  3.80399942e-01\n",
      " -1.50939479e-01 -2.21253082e-01 -1.62797704e-01  2.82289594e-01\n",
      "  1.86416935e-02 -1.10716291e-01 -4.48899150e-01  2.80089200e-01\n",
      " -2.68591136e-01 -1.42840639e-01  1.71275988e-01  2.69929439e-01\n",
      "  2.41198987e-02  8.65758434e-02 -1.35979593e-01  5.44472076e-02\n",
      "  2.77847081e-01 -3.89715999e-01 -3.23853433e-01 -3.71757871e-03\n",
      " -4.49987091e-02  1.87131152e-01 -7.25416362e-01 -2.34337822e-02\n",
      " -3.08492333e-01 -1.82816386e-01 -1.33403525e-01  1.92829654e-01\n",
      "  5.14104553e-02  1.46446437e-01 -4.20339823e-01  3.52952510e-01\n",
      " -1.58344463e-01  7.78484419e-02  1.82721063e-01  7.79171526e-01\n",
      " -1.46355376e-01  4.99421924e-01 -8.57707784e-02  2.21453324e-01\n",
      " -6.52330741e-02 -4.82995659e-01  7.11840093e-02 -9.79594216e-02\n",
      "  3.19412798e-01 -6.52370676e-02  3.02667826e-01 -4.15895820e-01\n",
      " -2.39654660e-01 -1.68479815e-01 -1.53124198e-01  1.12435870e-01\n",
      "  8.03593919e-02  2.75076419e-01 -1.96017012e-01  2.21531108e-01\n",
      "  1.81374803e-01  6.82803094e-01  1.96980909e-01  4.07810241e-01\n",
      "  2.53583118e-02 -1.32681340e-01 -7.43766502e-02  9.73829925e-02\n",
      "  6.52073249e-02  4.82696779e-02 -7.23088309e-02  2.92220026e-01\n",
      " -2.14981005e-01 -1.14434741e-01 -2.46388257e-01 -1.50840476e-01\n",
      "  8.10831413e-02  3.52807730e-01  2.00500060e-02  2.09875569e-01\n",
      "  1.44382358e-01 -4.75963682e-01  8.92526805e-02 -2.09552065e-01\n",
      "  2.28388086e-02 -3.92864585e-01  6.14037402e-02 -1.42480852e-02\n",
      " -1.36759236e-01  5.71351230e-01 -2.61955500e-01  9.64445546e-02\n",
      " -2.49447718e-01  2.10202917e-01  1.32042438e-01  2.33104706e-01\n",
      " -2.93684062e-02 -3.36317033e-01 -7.41453990e-02 -2.80087024e-01\n",
      "  2.14970246e-01 -3.48523498e-01 -9.27268267e-02  5.67516349e-02\n",
      "  6.49711266e-02  2.44049788e-01 -5.31102002e-01  2.82284439e-01\n",
      " -1.03400894e-01 -1.01255225e-02  2.89197434e-02  1.24749623e-01\n",
      "  1.39734849e-01 -3.49334270e-01 -8.43325779e-02  6.65675327e-02\n",
      "  4.29742247e-01 -2.00786486e-01  3.54918242e-01  1.44033298e-01\n",
      " -1.28279313e-01 -5.85383713e-01  1.43175080e-01  1.83027256e-02\n",
      " -6.94443360e-02 -7.60794654e-02 -1.60221532e-01 -1.87235013e-01\n",
      "  1.71377167e-01  2.14274619e-02 -3.16938102e-01 -2.67501205e-01\n",
      "  2.39992514e-01 -2.76013184e+00 -7.40004256e-02 -4.03931178e-02\n",
      " -2.24488869e-01 -6.58198744e-02  1.74672157e-02  1.43615410e-01\n",
      " -6.74141273e-02 -1.08691029e-01  1.19323187e-01 -2.15082884e-01\n",
      " -3.62610780e-02  1.65619537e-01  2.25950181e-01  9.01504233e-02\n",
      " -4.48476702e-01 -9.65100154e-02  3.03611130e-01  6.06460512e-01\n",
      " -1.26538873e-01 -7.40208477e-02  5.09501874e-01  1.21901989e-01\n",
      " -1.69241682e-01 -2.88332850e-01  2.48726249e-01  1.84205934e-01\n",
      " -8.99228528e-02  6.87380806e-02 -3.81447047e-01 -2.80365884e-01\n",
      " -3.54577869e-01  1.36310458e-01  8.34075212e-02 -3.48313481e-01\n",
      " -3.57590824e-01  2.43643239e-01  1.77999631e-01  1.69756413e+01\n",
      "  2.42056414e-01  3.83577161e-02 -4.47412223e-01  8.89120102e-01\n",
      "  1.96230307e-01 -6.31686971e-02 -4.01825041e-01  4.38249469e-01]\n"
     ]
    }
   ],
   "source": [
    "print(bertje_training_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          i2       0.00      0.00      0.00         1\n",
      "          i4       0.50      1.00      0.67         1\n",
      "          l2       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.50      0.67      0.56         3\n",
      "weighted avg       0.50      0.67      0.56         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "BERT_classifier = LinearSVC(random_state=0, tol=1e-5)\n",
    "BERT_classifier.fit(bertje_training_vectors, train_labels)\n",
    "SVM_predictions = list(BERT_classifier.predict(bertje_test_vectors))\n",
    "predicted_test_scores= BERT_classifier.decision_function(bertje_test_vectors) \n",
    "print(classification_report(test_labels, SVM_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering and similarity with BERTje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bertje_training_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1da03bb4354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclustering_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclustering_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbertje_training_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcluster_assignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bertje_training_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 2\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(bertje_training_vectors)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "print(cluster_assignment)\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(train_texts[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query sentences:\n",
    "queries = ['Fietsen lukt nog niet.', 'Eerste stapjes met lopen.', 'Neemt iedere dag de trap.']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 2\n",
    "for query in queries:\n",
    "    query_embedding = get_sentence_embedding_vector_from_layer(query, bertje_model, 0)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, bertje_training_vectors)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        print(train_texts[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
