{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from updates_join_annotations import open_df_from_tsv\n",
    "import updates_get_average_scores_per_label as scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, filename in enumerate(Path('./sample_data').glob('**/*.tsv')):\n",
    "    \"\"\"\n",
    "    Creates pd.DataFrame by joining files from different annotators and different documents to one\n",
    "    large df\n",
    "    \"\"\"\n",
    "    # Extract annotator name from doc\n",
    "    annotator = filename.stem\n",
    "    \n",
    "    # Use the first file to create df\n",
    "    if index == 0:\n",
    "        df = open_df_from_tsv(filename)\n",
    "        \n",
    "    # Update df with new files\n",
    "    else: \n",
    "        # Create temporary df\n",
    "        df_temp = open_df_from_tsv(filename)\n",
    "    \n",
    "        # if file is already in rows, and annotator is already in colmumns, then update\n",
    "        if df_temp['file_id'][1] in set(df['file_id']) and f'labels_{annotator}' in df.columns:\n",
    "            df.update(df_temp)\n",
    "        # Elif file is in rows (and annotator not yet in columns), then concat with axis=1\n",
    "        elif df_temp['file_id'][1] in set(df['file_id']):\n",
    "            df_temp.drop(['token_d_id', 'token', 'file_id', 'sent_id', 'token_s_id'], axis=1, inplace=True)\n",
    "            df = pd.concat([df, df_temp], axis=1, sort=False)\n",
    "        # Else\n",
    "        else:\n",
    "            df = pd.concat([df, df_temp], join='inner')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_d_id</th>\n",
       "      <th>token</th>\n",
       "      <th>temp</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_s_id</th>\n",
       "      <th>labels_bos</th>\n",
       "      <th>relation_bos</th>\n",
       "      <th>temp</th>\n",
       "      <th>labels_avelli</th>\n",
       "      <th>relation_avelli</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2546_0</th>\n",
       "      <td>0</td>\n",
       "      <td>Op</td>\n",
       "      <td>_</td>\n",
       "      <td>2546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>type\\_Background[1]</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546_1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dd-mm-jjjj</td>\n",
       "      <td>_</td>\n",
       "      <td>2546</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>type\\_Background[1]</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546_2</th>\n",
       "      <td>2</td>\n",
       "      <td>zag</td>\n",
       "      <td>_</td>\n",
       "      <td>2546</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>type\\_Background[1]</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546_3</th>\n",
       "      <td>3</td>\n",
       "      <td>ik</td>\n",
       "      <td>_</td>\n",
       "      <td>2546</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>type\\_Background[1]</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546_4</th>\n",
       "      <td>4</td>\n",
       "      <td>bovengenoemde</td>\n",
       "      <td>_</td>\n",
       "      <td>2546</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>type\\_Background[1]</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token_d_id          token temp file_id sent_id token_s_id labels_bos  \\\n",
       "2546_0          0             Op    _    2546       1          1          _   \n",
       "2546_1          1     Dd-mm-jjjj    _    2546       1          2          _   \n",
       "2546_2          2            zag    _    2546       1          3          _   \n",
       "2546_3          3             ik    _    2546       1          4          _   \n",
       "2546_4          4  bovengenoemde    _    2546       1          5          _   \n",
       "\n",
       "       relation_bos temp        labels_avelli relation_avelli temp  \n",
       "2546_0            _    _  type\\_Background[1]               _    _  \n",
       "2546_1            _    _  type\\_Background[1]               _    _  \n",
       "2546_2            _    _  type\\_Background[1]               _    _  \n",
       "2546_3            _    _  type\\_Background[1]               _    _  \n",
       "2546_4            _    _  type\\_Background[1]               _    _  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to pickle\n",
    "df.to_pickle('./sample_data/token_level_df_all_annotators_all_docs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read file\n",
    "# df = pd.read_pickle('./sample_data/token_level_df_all_annotators_all_docs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'isempty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5fa34d39ce7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mannotator_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'avelli'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meskers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframeForThree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotator_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# get personal dicts per annotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/COVID-19-TM/UMC-COVID-FUND/code/a-proof/updates_get_average_scores_per_label.py\u001b[0m in \u001b[0;36mget_dataframeForThree\u001b[0;34m(df, annotator_names)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# get dictionaries per annotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mdict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_annotator_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mannotator_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mdict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_annotator_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mannotator_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mdict3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_annotator_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mannotator_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/COVID-19-TM/UMC-COVID-FUND/code/a-proof/updates_get_average_scores_per_label.py\u001b[0m in \u001b[0;36mget_annotator_dict\u001b[0;34m(df, annotator)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m#create empty dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mannotator_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mannotator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mannotator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#check where label is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'isempty'"
     ]
    }
   ],
   "source": [
    "## Testing on 3 annotators\n",
    "df = pd.read_pickle('./sample_data/token_level_df_all_annotators_all_docs.pkl')\n",
    "annotator_names = ['avelli', 'bos', 'meskers']\n",
    "    \n",
    "new_df = scores.get_dataframeForThree(df, annotator_names)\n",
    "\n",
    "# get personal dicts per annotator\n",
    "dict_a1 = scores.get_annotator_dict(df, 'labels_'+annotator_names[0])\n",
    "dict_a2 = scores.get_annotator_dict(df, 'labels_'+annotator_names[1])\n",
    "dict_a3 = scores.get_annotator_dict(df, 'labels_'+annotator_names[2])\n",
    "    \n",
    "# score the annotations in the df\n",
    "new_df = scores.find_matches(new_df, annotator_names[0], dict_a1)\n",
    "new_df = scores.find_matches(new_df, annotator_names[1], dict_a2)\n",
    "new_df = scores.find_matches(new_df, annotator_names[2], dict_a3)\n",
    "    \n",
    "# sum the scores and put in new column\n",
    "new_df['score'] = new_df[annotator_names[0]]+new_df[annotator_names[1]]+new_df[annotator_names[2]]+new_df[annotator_names[3]]\n",
    "new_df.to_excel('excel_with_scores.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-932134c70283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mannotator_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'avelli'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'katsburg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meskers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opsomer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swartjes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vanderpas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vervaart'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotator_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# get personal dicts per annotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/COVID-19-TM/UMC-COVID-FUND/code/a-proof/updates_get_average_scores_per_label.py\u001b[0m in \u001b[0;36mget_dataframe\u001b[0;34m(df, annotator_names)\u001b[0m\n\u001b[1;32m    126\u001b[0m      \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mannotator_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstrings\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccordance\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcolumnnames\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mannotators\u001b[0m\u001b[0;31m'\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     '''\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;31m# get dictionaries per annotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mdict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_annotator_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mannotator_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/COVID-19-TM/UMC-COVID-FUND/code/a-proof/updates_get_average_scores_per_label.py\u001b[0m in \u001b[0;36mget_annotator_dict\u001b[0;34m(df, columname)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mspan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    " # list annotator names\n",
    "annotator_names = ['avelli', 'bos', 'katsburg', 'meskers', 'opsomer', 'swartjes', 'vanderpas', 'vervaart']\n",
    "    \n",
    "new_df = scores.get_dataframeForAll(df, annotator_names)\n",
    "    \n",
    "# get personal dicts per annotator\n",
    "dict_a1 = scores.get_annotator_dict(df, 'labels_'+annotator_names[0])\n",
    "dict_a2 = scores.get_annotator_dict(df, 'labels_'+annotator_names[1])\n",
    "dict_a3 = scores.get_annotator_dict(df, 'labels_'+annotator_names[2])\n",
    "dict_a4 = scores.get_annotator_dict(df, 'labels_'+annotator_names[3])\n",
    "dict_a5 = scores.get_annotator_dict(df, 'labels_'+annotator_names[4])\n",
    "dict_a6 = scores.get_annotator_dict(df, 'labels_'+annotator_names[5])\n",
    "dict_a7 = scores.get_annotator_dict(df, 'labels_'+annotator_names[6])\n",
    "dict_a8 = scores.get_annotator_dict(df, 'labels_'+annotator_names[7])\n",
    "    \n",
    "# score the annotations in the df\n",
    "new_df = scores.find_matches(new_df, annotator_names[0], dict_a1)\n",
    "new_df = scores.find_matches(new_df, annotator_names[1], dict_a2)\n",
    "new_df = scores.find_matches(new_df, annotator_names[2], dict_a3)\n",
    "new_df = scores.find_matches(new_df, annotator_names[3], dict_a4)\n",
    "new_df = scores.find_matches(new_df, annotator_names[4], dict_a5)\n",
    "new_df = scores.find_matches(new_df, annotator_names[5], dict_a6)\n",
    "new_df = scores.find_matches(new_df, annotator_names[6], dict_a7)\n",
    "new_df = scores.find_matches(new_df, annotator_names[7], dict_a8)\n",
    "    \n",
    "# sum the scores and put in new column\n",
    "new_df['score'] = new_df[annotator_names[0]]+new_df[annotator_names[1]]+new_df[annotator_names[2]]+new_df[annotator_names[3]]+new_df[annotator_names[4]]+new_df[annotator_names[5]]+new_df[annotator_names[6]]+new_df[annotator_names[7]]+new_df[annotator_names[8]]\n",
    "new_df.to_excel('excel_with_scores.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(new_df):\n",
    "# extract average scores per label\n",
    "    print('average scores domains:')\n",
    "    print('average score Stemming: '+ str(get_average_score_per_label(new_df, 'Stemming')))\n",
    "    print('average score Lopen: '+ str(get_average_score_per_label(new_df, 'Lopen')))\n",
    "    print('average score Beroep en Werk: '+str(get_average_score_per_label(new_df, 'Beroep')))\n",
    "    print('average score Inspanningstolerantie: '+str(get_average_score_per_label(new_df, 'Inspanningstolerantie')))\n",
    "    print()\n",
    "    print('average scores levels:')\n",
    "    print('average score FAC 0: '+ str(get_average_score_per_label(new_df, 'FAC 2')))\n",
    "    print('average score FAC 1: '+ str(get_average_score_per_label(new_df, 'FAC 1')))\n",
    "    print('average score FAC 2: '+ str(get_average_score_per_label(new_df, 'FAC 2')))\n",
    "    print('average score FAC 3: '+ str(get_average_score_per_label(new_df, 'FAC 2')))\n",
    "    print('average score FAC 4: '+ str(get_average_score_per_label(new_df, 'FAC 4')))\n",
    "    print('average score FAC 5: '+ str(get_average_score_per_label(new_df, 'FAC 5')))\n",
    "    print()\n",
    "    print('average score STM 0: '+ str(get_average_score_per_label(new_df, 'STM 0')))\n",
    "    print('average score STM 1: '+ str(get_average_score_per_label(new_df, 'STM 1')))\n",
    "    print('average score STM 2: '+ str(get_average_score_per_label(new_df, 'STM 2')))\n",
    "    print('average score STM 3: '+ str(get_average_score_per_label(new_df, 'STM 3')))\n",
    "    print('average score STM 4: '+ str(get_average_score_per_label(new_df, 'STM 4')))\n",
    "    print('average score STM 5: '+ str(get_average_score_per_label(new_df, 'STM 5')))\n",
    "    print()\n",
    "    print('average score INS 0: '+ str(get_average_score_per_label(new_df, 'INS 0')))\n",
    "    print('average score INS 1: '+ str(get_average_score_per_label(new_df, 'INS 1')))\n",
    "    print('average score INS 2: '+ str(get_average_score_per_label(new_df, 'INS 2')))\n",
    "    print('average score INS 3: '+ str(get_average_score_per_label(new_df, 'INS 3')))\n",
    "    print('average score INS 4: '+ str(get_average_score_per_label(new_df, 'INS 4')))\n",
    "    print()\n",
    "    print('average score BER 0: '+ str(get_average_score_per_label(new_df, 'BER 0')))\n",
    "    print('average score BER 1: '+ str(get_average_score_per_label(new_df, 'BER 1')))\n",
    "    print('average score BER 2: '+ str(get_average_score_per_label(new_df, 'BER 2')))\n",
    "    print('average score BER 3: '+ str(get_average_score_per_label(new_df, 'BER 3')))\n",
    "    print('average score BER 4: '+ str(get_average_score_per_label(new_df, 'BER 4')))\n",
    "    print()\n",
    "    print('average score remaining labels')\n",
    "    print('average score stm\\_reaction: '+ str(get_average_score_per_label(new_df, 'reaction')))\n",
    "    print('average score type\\_Background: '+ str(get_average_score_per_label(new_df, 'Background')))\n",
    "    print('average score view\\_Patient: '+ str(get_average_score_per_label(new_df, 'Patient')))\n",
    "    print('average score view\\_Thirdparty: '+ str(get_average_score_per_label(new_df, 'Third')))\n",
    "    print('average score type\\_Implicit: '+ str(get_average_score_per_label(new_df, 'Implicit')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-36f09d55a960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "print_scores(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
